{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3215225e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You are in: Singularity | singularity_proj_combeffect\n",
      "    BASE DIRECTORY:     /mount/work\n",
      "    PATH OF SOURCE:     /mount/work/source\n",
      "    PATH OF EXECUTABLE: /mount/work/exe\n",
      "    PATH OF ANNOTATION: /mount/work/annotation\n",
      "    PATH OF PROJECT:    /mount/project\n",
      "    PATH OF RESULTS:    /mount/work/out/proj_combeffect\n",
      "\n",
      "Library imported:\n",
      "    numpy, pandas, matplotlib.pyplot\n",
      "    os, sys, time, gzip, glob\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append('../')\n",
    "from config_sing import *\n",
    "show_env()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fae8cba8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlite3\n",
    "import itertools as it\n",
    "from collections import defaultdict\n",
    "import matplotlib as mpl\n",
    "from matplotlib.lines import Line2D\n",
    "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "plt.style.use(\"seaborn-whitegrid\")\n",
    "\n",
    "import math\n",
    "import random\n",
    "import json\n",
    "from sklearn.manifold import TSNE\n",
    "from functools import partial, reduce\n",
    "print = partial(print, flush=True)\n",
    "\n",
    "### Set Samples\n",
    "fun = np.core.defchararray.add\n",
    "idx = np.arange(1,6).astype(\"str\")\n",
    "\n",
    "INPUT    = reduce(fun, [\"Input\", idx])\n",
    "INPUT20X = reduce(fun, [\"Input\", idx,     \"_20x\"])\n",
    "TFX_DMSO = reduce(fun, [\"TFX\",   idx[1:], \"_DMSO\"])\n",
    "TFX_DEX  = reduce(fun, [\"TFX\",   idx[1:], \"_Dex\"])\n",
    "SAMPLES  = np.concatenate([INPUT20X, TFX_DMSO, TFX_DEX])\n",
    "SAMPLES_OUT = np.concatenate([TFX_DMSO, TFX_DEX])\n",
    "GROUPS   = [\"Input\", \"Input_20x\", \"TFX_DMSO\", \"TFX_Dex\"]\n",
    "\n",
    "### file path of database\n",
    "fdiry = os.path.join(FD_RES, 'database')\n",
    "fname = \"fragment_chr17.db\"\n",
    "FPATH_DB = os.path.join(fdiry, fname)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a65b5e00",
   "metadata": {},
   "source": [
    "## test stream fragments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "18d9ec2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prep_line(line):\n",
    "    cnames = (\n",
    "        \"Frag_Chrom\", \n",
    "        \"Frag_Start\", \n",
    "        \"Frag_End\", \n",
    "        \"Frag_Count\", \n",
    "        \"Region_Chrom\", \n",
    "        \"Region_Start\", \n",
    "        \"Region_End\",\n",
    "        \"Region_Name\", \n",
    "        \"Region_Score\",\n",
    "        \"Region_Strand\",\n",
    "        \"Overlap\")\n",
    "    lst = line.decode('ASCII').strip().split('\\t')  \n",
    "    dct = dict(zip(cnames, lst))\n",
    "    fragment = \"_\".join([dct[\"Frag_Chrom\"],   dct[\"Frag_Start\"],   dct[\"Frag_End\"]]) \n",
    "    region   = \"_\".join([dct[\"Region_Chrom\"], dct[\"Region_Start\"], dct[\"Region_End\"]]) \n",
    "    return fragment, region\n",
    "\n",
    "### helper function to get a chunk of file\n",
    "def get_chunks(gen, rows=10):\n",
    "    \"\"\"Divides the data into #rows in each list\"\"\"\n",
    "    iterable = iter(gen)\n",
    "    while True:\n",
    "        x = list(it.islice(iterable, rows))\n",
    "        if not x:\n",
    "            return\n",
    "        yield x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c7728783",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/mount/work/out/proj_combeffect/count_fragment/TFX2_DMSO/region_dex_GR_P300_dnase_chr17.bed.gz\n",
      "b'chr17\\t6001570\\t6002624\\t2\\tchr17\\t6002561\\t6003866\\tchr17:6002561-6003866\\t.\\t.\\t63\\n'\n",
      "b'chr17\\t6001571\\t6002624\\t1\\tchr17\\t6002561\\t6003866\\tchr17:6002561-6003866\\t.\\t.\\t63\\n'\n",
      "b'chr17\\t6001762\\t6002691\\t2\\tchr17\\t6002561\\t6003866\\tchr17:6002561-6003866\\t.\\t.\\t130\\n'\n",
      "b'chr17\\t6001762\\t6002692\\t1\\tchr17\\t6002561\\t6003866\\tchr17:6002561-6003866\\t.\\t.\\t131\\n'\n",
      "b'chr17\\t6001763\\t6002692\\t1\\tchr17\\t6002561\\t6003866\\tchr17:6002561-6003866\\t.\\t.\\t131\\n'\n",
      "b'chr17\\t6001765\\t6002692\\t1\\tchr17\\t6002561\\t6003866\\tchr17:6002561-6003866\\t.\\t.\\t131\\n'\n",
      "b'chr17\\t6001969\\t6002895\\t1\\tchr17\\t6002561\\t6003866\\tchr17:6002561-6003866\\t.\\t.\\t334\\n'\n",
      "b'chr17\\t6001969\\t6002896\\t1\\tchr17\\t6002561\\t6003866\\tchr17:6002561-6003866\\t.\\t.\\t335\\n'\n",
      "b'chr17\\t6001970\\t6002896\\t1\\tchr17\\t6002561\\t6003866\\tchr17:6002561-6003866\\t.\\t.\\t335\\n'\n",
      "b'chr17\\t6002054\\t6002943\\t2\\tchr17\\t6002561\\t6003866\\tchr17:6002561-6003866\\t.\\t.\\t382\\n'\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['chr17_6001570_6002624',\n",
       " 'chr17_6001571_6002624',\n",
       " 'chr17_6001762_6002691',\n",
       " 'chr17_6001762_6002692',\n",
       " 'chr17_6001763_6002692',\n",
       " 'chr17_6001765_6002692',\n",
       " 'chr17_6001969_6002895',\n",
       " 'chr17_6001969_6002896',\n",
       " 'chr17_6001970_6002896',\n",
       " 'chr17_6002054_6002943']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fdiry = os.path.join(FD_RES, \"count_fragment\", \"TFX2_DMSO\")\n",
    "fname = \"region_dex_GR_P300_dnase_chr17.bed.gz\"\n",
    "fpath = os.path.join(fdiry, fname)\n",
    "print(fpath)\n",
    "\n",
    "frgs = []\n",
    "with gzip.open(fpath, 'rb') as file:\n",
    "    chunks = get_chunks(file)\n",
    "    chunk  = next(chunks)\n",
    "    for line in chunk:\n",
    "        print(line)\n",
    "        frg, reg = prep_line(line)\n",
    "        frgs.append(frg)\n",
    "        \n",
    "frgs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "408be8c3",
   "metadata": {},
   "source": [
    "## Annotation: motif"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6808a189",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_annot(frgs, fpath_db=FPATH_DB):\n",
    "    \"\"\"get annotation from the given fragments\"\"\"\n",
    "    ### set query\n",
    "    txt   = ', '.join('?' for _ in frgs)\n",
    "    query = f\"\"\"\n",
    "        SELECT   Ant.Fragment, Mtf.motif, Mtf.score\n",
    "        FROM     Annotation Ant\n",
    "        JOIN     Motif      Mtf \n",
    "        ON       Ant.binding = Mtf.binding\n",
    "        WHERE    Ant.Fragment IN ({txt})\n",
    "        ORDER BY Ant.Fragment\n",
    "        \"\"\"\n",
    "    \n",
    "    ## query out from database\n",
    "    with sqlite3.connect(fpath_db) as conn:\n",
    "        cursor = conn.cursor()    \n",
    "        cursor = cursor.execute(query, frgs)\n",
    "        \n",
    "    ### summarize the motif annotation scores\n",
    "    dct_ann_count = defaultdict(lambda: defaultdict(lambda: 0))\n",
    "    dct_ann_score = defaultdict(lambda: defaultdict(lambda: 0.0))\n",
    "    \n",
    "    for row in cursor:\n",
    "        ### parse info\n",
    "        frg, mtf, val = row\n",
    "        \n",
    "        ### count and sum the annotation scores\n",
    "        dct_ann_count[frg][mtf] += 1\n",
    "        dct_ann_score[frg][mtf] += val\n",
    "    \n",
    "    ### arrange and return\n",
    "    dct_ann = dict()\n",
    "    dct_ann[\"count\"] = dct_ann_count\n",
    "    dct_ann[\"score\"] = dct_ann_score\n",
    "    return dct_ann"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a1f67c4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "dct_ann = get_annot(frgs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1962d35f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "chr17_6001570_6002624\n",
      "{'HD/23': 1, 'SOX/1': 2, 'EVI1/MECOM': 1, 'ZNF768': 1, 'NFY': 1, 'EBF1': 1, 'GC-tract': 8, 'ZNF320': 2, 'CTCF': 2, 'KLF/SP/2': 9, 'INSM1': 1, 'ETS/2': 4, 'ZBTB48': 1, 'Ebox/CAGATGG': 2, 'HEN1': 4, 'OSR2': 2, 'Ebox/CAGCTG': 3, 'NR/3': 5, 'NR/15': 2, 'KLF/SP/1': 3, 'GLI': 1, 'ZNF53': 2, 'TFAP2/1': 4, 'NR/16': 2, 'PRDM14': 1, 'ZIC': 1, 'Ebox/CACCTG': 1, 'IRF/2': 4, 'ZIM3': 1, 'ZNF354': 2, 'YY1': 3, 'HD/14': 2, 'RFX/1': 2, 'ZNF549': 2, 'FEZF1': 2, 'GCM': 1, 'SIX/1': 1, 'HIC/1': 3, 'P53-like/1': 2, 'ZNF449': 2, 'ZNF143': 3, 'NR/17': 5, 'TBX/4': 2, 'AP1/1': 2, 'SMAD': 4, 'PAX/2': 2, 'MAF': 1, 'HD/20': 3, 'HD/22': 4, 'TBX/3': 2, 'ZFX': 3, 'PLAG1': 1, 'ZNF324': 2, 'AP1/2': 2, 'ZNF554': 3, 'NR/18': 1, 'NFKB/2': 1, 'Ebox/CACGTG/1': 3, 'SREBF1': 2, 'GRHL': 1, 'ZFN121': 2, 'NR/19': 2, 'MEF2': 1, 'FOX/5': 1, 'HD/2': 3, 'EGR': 1, 'REST/NRSF': 1, 'ZNF335': 1, 'PAX/1': 1, 'POU/3': 1, 'ZNF257': 1, 'E2F/2': 3, 'MFZ1': 2, 'HINFP1/1': 1, 'GFI': 1, 'ZNF146': 1, 'E2F/1': 1, 'CCAAT/CEBP': 1, 'ZNF140': 1, 'ZNF274': 1, 'DDIT3+CEBPA': 1, 'ZSCAN3': 1, 'SMARCA5': 1, 'MTF1': 1, 'HIC/2': 2, 'IRF/1': 2, 'CENBP': 2, 'FOX/4': 1, 'FOX/7': 1, 'MZF1': 2, 'NR/1': 2, 'ZIC/2': 1, 'REL-halfsite': 1, 'HD/12': 1, 'ZNF436': 1, 'LEF1': 1, 'ETS/1': 1, 'ZNF332': 1, 'PAX-halfsite': 1, 'NR/11': 2, 'NR/7': 2, 'ZNF680': 1, 'NFI/1': 1, 'NFI/3': 2, 'FOX/1': 1, 'POU/1': 1, 'NR/12': 1, 'HD/21': 1, 'TCF/LEF': 1, 'HD/6': 1, 'HD/4': 1, 'HD/8': 1, 'MYB/2': 1, 'HD/18': 2, 'HD/3': 1, 'RUNX/1': 1, 'ZNF547': 1, 'HD/16': 1, 'ZBTB6': 1, 'ZNF136': 1, 'SNAI2': 1, 'ZNF331': 1, 'MECP2': 1, 'ZNF329': 1, 'NR/10': 1, 'ZNF490': 1, 'BCL6/1': 1, 'BCL6/2': 1, 'STAT/2': 1}\n"
     ]
    }
   ],
   "source": [
    "dct_ann_count = dct_ann[\"count\"]\n",
    "#dct_ann_count = {k:dict(v) for k,v in dct_ann_count.items()}\n",
    "for k,v in dct_ann_count.items():\n",
    "    print(k)\n",
    "    print(str(dict(v)))\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "0ac3ba3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/mount/work/out/proj_combeffect/count_fragment/TFX2_DMSO/region_dex_GR_P300_dnase_chr17.bed.gz\n",
      "/mount/work/out/proj_combeffect/scratch/region_dex_GR_P300_dnase_chr17/TFX2_DMSO_motif_count.tsv\n",
      "/mount/work/out/proj_combeffect/scratch/region_dex_GR_P300_dnase_chr17/TFX2_DMSO_motif_score.tsv\n",
      "\n",
      "/mount/work/out/proj_combeffect/count_fragment/TFX3_DMSO/region_dex_GR_P300_dnase_chr17.bed.gz\n",
      "/mount/work/out/proj_combeffect/scratch/region_dex_GR_P300_dnase_chr17/TFX3_DMSO_motif_count.tsv\n",
      "/mount/work/out/proj_combeffect/scratch/region_dex_GR_P300_dnase_chr17/TFX3_DMSO_motif_score.tsv\n",
      "\n",
      "/mount/work/out/proj_combeffect/count_fragment/TFX4_DMSO/region_dex_GR_P300_dnase_chr17.bed.gz\n",
      "/mount/work/out/proj_combeffect/scratch/region_dex_GR_P300_dnase_chr17/TFX4_DMSO_motif_count.tsv\n",
      "/mount/work/out/proj_combeffect/scratch/region_dex_GR_P300_dnase_chr17/TFX4_DMSO_motif_score.tsv\n",
      "\n",
      "/mount/work/out/proj_combeffect/count_fragment/TFX5_DMSO/region_dex_GR_P300_dnase_chr17.bed.gz\n",
      "/mount/work/out/proj_combeffect/scratch/region_dex_GR_P300_dnase_chr17/TFX5_DMSO_motif_count.tsv\n",
      "/mount/work/out/proj_combeffect/scratch/region_dex_GR_P300_dnase_chr17/TFX5_DMSO_motif_score.tsv\n",
      "\n",
      "/mount/work/out/proj_combeffect/count_fragment/TFX2_Dex/region_dex_GR_P300_dnase_chr17.bed.gz\n",
      "/mount/work/out/proj_combeffect/scratch/region_dex_GR_P300_dnase_chr17/TFX2_Dex_motif_count.tsv\n",
      "/mount/work/out/proj_combeffect/scratch/region_dex_GR_P300_dnase_chr17/TFX2_Dex_motif_score.tsv\n",
      "\n",
      "/mount/work/out/proj_combeffect/count_fragment/TFX3_Dex/region_dex_GR_P300_dnase_chr17.bed.gz\n",
      "/mount/work/out/proj_combeffect/scratch/region_dex_GR_P300_dnase_chr17/TFX3_Dex_motif_count.tsv\n",
      "/mount/work/out/proj_combeffect/scratch/region_dex_GR_P300_dnase_chr17/TFX3_Dex_motif_score.tsv\n",
      "\n",
      "/mount/work/out/proj_combeffect/count_fragment/TFX4_Dex/region_dex_GR_P300_dnase_chr17.bed.gz\n",
      "/mount/work/out/proj_combeffect/scratch/region_dex_GR_P300_dnase_chr17/TFX4_Dex_motif_count.tsv\n",
      "/mount/work/out/proj_combeffect/scratch/region_dex_GR_P300_dnase_chr17/TFX4_Dex_motif_score.tsv\n",
      "\n",
      "/mount/work/out/proj_combeffect/count_fragment/TFX5_Dex/region_dex_GR_P300_dnase_chr17.bed.gz\n",
      "/mount/work/out/proj_combeffect/scratch/region_dex_GR_P300_dnase_chr17/TFX5_Dex_motif_count.tsv\n",
      "/mount/work/out/proj_combeffect/scratch/region_dex_GR_P300_dnase_chr17/TFX5_Dex_motif_score.tsv\n",
      "\n",
      "CPU times: user 1min 31s, sys: 3.94 s, total: 1min 35s\n",
      "Wall time: 12min 19s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "for sample in SAMPLES_OUT:\n",
    "\n",
    "    ### input file\n",
    "    fdiry = os.path.join(FD_RES, \"count_fragment\", sample)\n",
    "    fname = \"region_dex_GR_P300_dnase_chr17.bed.gz\"\n",
    "    fpath_inp = os.path.join(fdiry, fname)\n",
    "\n",
    "    ### output file\n",
    "    fdiry = os.path.join(FD_RES, \"scratch\", \"region_dex_GR_P300_dnase_chr17\")\n",
    "    fname = f\"{sample}_motif_count.tsv\"\n",
    "    fpath_out_cnt = os.path.join(fdiry, fname)\n",
    "\n",
    "    ### output file\n",
    "    fdiry = os.path.join(FD_RES, \"scratch\", \"region_dex_GR_P300_dnase_chr17\")\n",
    "    fname = f\"{sample}_motif_score.tsv\"\n",
    "    fpath_out_scr = os.path.join(fdiry, fname)\n",
    "\n",
    "    \n",
    "    ### show file IO\n",
    "    print(fpath_inp)\n",
    "    print(fpath_out_cnt)\n",
    "    print(fpath_out_scr)\n",
    "\n",
    "    with gzip.open(fpath_inp, 'rb') as finp, open(fpath_out_cnt, 'w') as fout_cnt, open(fpath_out_scr, 'w') as fout_scr:\n",
    "        ### set chunks\n",
    "        chunks = get_chunks(finp)\n",
    "\n",
    "        ### loop through each chunk\n",
    "        for chunk in chunks:\n",
    "            ### get fragments\n",
    "            frgs = []\n",
    "            for line in chunk:\n",
    "                frg, reg = prep_line(line)\n",
    "                frgs.append(frg)\n",
    "\n",
    "            ### get motif from database\n",
    "            dct_ann = get_annot(frgs)\n",
    "            \n",
    "            ### output count\n",
    "            dct_ann_count = dct_ann[\"count\"]\n",
    "            dct_ann_score = dct_ann[\"score\"]\n",
    "\n",
    "            for key, val in dct_ann_count.items():\n",
    "                ### output to a line\n",
    "                line = \"\\t\".join([key, json.dumps(val)])\n",
    "                fout_cnt.write(line + \"\\n\")\n",
    "                #print(line)\n",
    "                #break\n",
    "                \n",
    "            for key, val in dct_ann_score.items():\n",
    "                ### round the values\n",
    "                val = {k:np.round(v, decimals=5) for k, v in val.items()}\n",
    "\n",
    "                ### output to a line\n",
    "                line = \"\\t\".join([key, json.dumps(val)])\n",
    "                fout_scr.write(line + \"\\n\")\n",
    "                #print(line)\n",
    "                #break\n",
    "            #break       \n",
    "        #break\n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab96c05a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
