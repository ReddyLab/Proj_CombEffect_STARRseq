{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9fe75517-cbf6-4e8e-8627-baf4da75222a",
   "metadata": {},
   "source": [
    "## Build Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a688e170-7870-4496-a95d-99c9da9f19fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "cat > ./model.stan << EOF\n",
    "data {\n",
    "    int <lower=1> NUM_DATA;\n",
    "    int <lower=1> NUM_FRAG;\n",
    "    int <lower=1> NUM_SEG;\n",
    "    int <lower=1> NUM_SEG_PER_FRAG;\n",
    "    int <lower=1> NUM_REP;\n",
    "    \n",
    "    int <lower=0> OUTPUT[NUM_DATA];\n",
    "    int <lower=1> INPUT[NUM_DATA];\n",
    "    real <lower=0> PHI;\n",
    "    \n",
    "    int L_DNA; // DNA library size\n",
    "    int L_RNA; // RNA library size\n",
    "    real shrinkageVar; // variance of shrinkage prior on effect sizes\n",
    "}\n",
    "\n",
    "transformed data {\n",
    "   real l_rna=L_RNA; real l_dna=L_DNA;\n",
    "   real LIB_RATIO=l_rna/l_dna;\n",
    "}\n",
    "\n",
    "parameters {\n",
    "    real<lower=0.0001> gamma[NUM_SEG]; // effect size of each fragment\n",
    "}\n",
    "\n",
    "model {\n",
    "    // Compute prefix-sum array for log(gamma)\n",
    "    real PSA[NUM_SEG + 1];\n",
    "    PSA[1]=0;\n",
    "    for(i in 2:(NUM_SEG+1)){\n",
    "        PSA[i]=PSA[i-1]+log(gamma[i-1]);\n",
    "    }\n",
    "    \n",
    "    // shrinkage prior on effect sizes\n",
    "    for(i in 1:NUM_SEG){\n",
    "        gamma[i] ~ lognormal(0, shrinkageVar);    \n",
    "    }\n",
    "    \n",
    "    // Likelihood\n",
    "    for (i in 1:NUM_FRAG) {\n",
    "        \n",
    "        // gather effect from corresponding segments\n",
    "        real gammaProd = exp(PSA[i + NUM_SEG_PER_FRAG] - PSA[i]);\n",
    "        \n",
    "        // mean(output) := segment effect x input x library ratio\n",
    "        for (k in 1:NUM_REP) {\n",
    "            int idx_data = NUM_FRAG * (i - 1) + k;\n",
    "            OUTPUT[idx_data] ~ neg_binomial_2(INPUT[idx_data] * LIB_RATIO * gammaProd, PHI);\n",
    "            \n",
    "            //print(seg_effect, \" \", INPUT[idx_data], \" \", INPUT[idx_data] * seg_effect);\n",
    "        } \n",
    "    }\n",
    "}\n",
    "EOF"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77477ccc-c319-4900-9882-0b8055a85170",
   "metadata": {},
   "source": [
    "**Check**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "26c7986f-84db-4575-a98f-da25e2e07665",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data {\n",
      "    int <lower=1> NUM_DATA;\n",
      "    int <lower=1> NUM_FRAG;\n",
      "    int <lower=1> NUM_SEG;\n",
      "    int <lower=1> NUM_SEG_PER_FRAG;\n",
      "    int <lower=1> NUM_REP;\n",
      "    \n",
      "    int <lower=0> OUTPUT[NUM_DATA];\n",
      "    int <lower=1> INPUT[NUM_DATA];\n",
      "    real <lower=0> PHI;\n",
      "    \n",
      "    int L_DNA; // DNA library size\n",
      "    int L_RNA; // RNA library size\n",
      "    real shrinkageVar; // variance of shrinkage prior on effect sizes\n",
      "}\n",
      "\n",
      "transformed data {\n",
      "   real l_rna=L_RNA; real l_dna=L_DNA;\n",
      "   real LIB_RATIO=l_rna/l_dna;\n",
      "}\n",
      "\n",
      "parameters {\n",
      "    real<lower=0.0001> gamma[NUM_SEG]; // effect size of each fragment\n",
      "}\n",
      "\n",
      "model {\n",
      "    // Compute prefix-sum array for log(gamma)\n",
      "    real PSA[NUM_SEG + 1];\n",
      "    PSA[1]=0;\n",
      "    for(i in 2:(NUM_SEG+1)){\n",
      "        PSA[i]=PSA[i-1]+log(gamma[i-1]);\n",
      "    }\n",
      "    \n",
      "    // shrinkage prior on effect sizes\n",
      "    for(i in 1:NUM_SEG){\n",
      "        gamma[i] ~ lognormal(0, shrinkageVar);    \n",
      "    }\n",
      "    \n",
      "    // Likelihood\n",
      "    for (i in 1:NUM_FRAG) {\n",
      "        \n",
      "        // gather effect from corresponding segments\n",
      "        real gammaProd = exp(PSA[i + NUM_SEG_PER_FRAG] - PSA[i]);\n",
      "        \n",
      "        // mean(output) := segment effect x input x library ratio\n",
      "        for (k in 1:NUM_REP) {\n",
      "            int idx_data = NUM_FRAG * (i - 1) + k;\n",
      "            OUTPUT[idx_data] ~ neg_binomial_2(INPUT[idx_data] * LIB_RATIO * gammaProd, PHI);\n",
      "            \n",
      "            //print(seg_effect, \" \", INPUT[idx_data], \" \", INPUT[idx_data] * seg_effect);\n",
      "        } \n",
      "    }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "cat ./model.stan"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29e5157a-6182-4d51-a900-9a93a6dd9891",
   "metadata": {},
   "source": [
    "**Compile model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2e725260-bd44-4561-a351-a19749e878db",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "make: Entering directory '/work/kk319/exe/cmdstan'\n",
      "\n",
      "--- Translating Stan model to C++ code ---\n",
      "bin/stanc  --o=/hpc/home/kk319/GitRepo/Proj_CombEffect_STARRseq/notebooks/12_model_sliding/model.hpp /hpc/home/kk319/GitRepo/Proj_CombEffect_STARRseq/notebooks/12_model_sliding/model.stan\n",
      "\n",
      "--- Compiling, linking C++ code ---\n",
      "g++ -std=c++1y -pthread -D_REENTRANT -Wno-sign-compare -Wno-ignored-attributes      -I stan/lib/stan_math/lib/tbb_2020.3/include   -O3 -I src -I stan/src -I lib/rapidjson_1.1.0/ -I lib/CLI11-1.9.1/ -I stan/lib/stan_math/ -I stan/lib/stan_math/lib/eigen_3.3.9 -I stan/lib/stan_math/lib/boost_1.75.0 -I stan/lib/stan_math/lib/sundials_5.7.0/include    -DBOOST_DISABLE_ASSERTS         -c -Wno-ignored-attributes   -x c++ -o /hpc/home/kk319/GitRepo/Proj_CombEffect_STARRseq/notebooks/12_model_sliding/model.o /hpc/home/kk319/GitRepo/Proj_CombEffect_STARRseq/notebooks/12_model_sliding/model.hpp\n",
      "g++ -std=c++1y -pthread -D_REENTRANT -Wno-sign-compare -Wno-ignored-attributes      -I stan/lib/stan_math/lib/tbb_2020.3/include   -O3 -I src -I stan/src -I lib/rapidjson_1.1.0/ -I lib/CLI11-1.9.1/ -I stan/lib/stan_math/ -I stan/lib/stan_math/lib/eigen_3.3.9 -I stan/lib/stan_math/lib/boost_1.75.0 -I stan/lib/stan_math/lib/sundials_5.7.0/include    -DBOOST_DISABLE_ASSERTS               -Wl,-L,\"/work/kk319/exe/cmdstan/stan/lib/stan_math/lib/tbb\" -Wl,-rpath,\"/work/kk319/exe/cmdstan/stan/lib/stan_math/lib/tbb\"      /hpc/home/kk319/GitRepo/Proj_CombEffect_STARRseq/notebooks/12_model_sliding/model.o src/cmdstan/main.o        -Wl,-L,\"/work/kk319/exe/cmdstan/stan/lib/stan_math/lib/tbb\" -Wl,-rpath,\"/work/kk319/exe/cmdstan/stan/lib/stan_math/lib/tbb\"   stan/lib/stan_math/lib/sundials_5.7.0/lib/libsundials_nvecserial.a stan/lib/stan_math/lib/sundials_5.7.0/lib/libsundials_cvodes.a stan/lib/stan_math/lib/sundials_5.7.0/lib/libsundials_idas.a stan/lib/stan_math/lib/sundials_5.7.0/lib/libsundials_kinsol.a  stan/lib/stan_math/lib/tbb/libtbb.so.2 -o /hpc/home/kk319/GitRepo/Proj_CombEffect_STARRseq/notebooks/12_model_sliding/model\n",
      "rm -f /hpc/home/kk319/GitRepo/Proj_CombEffect_STARRseq/notebooks/12_model_sliding/model.o\n",
      "make: Leaving directory '/work/kk319/exe/cmdstan'\n"
     ]
    }
   ],
   "source": [
    "source ../config.sh\n",
    "FD_CUR=$(pwd)\n",
    "\n",
    "make -C ${STAN_PATH} ${FD_CUR}/model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddc14f92-be7a-453e-98fa-21e90ccbcffe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8f5b6ab3-5ff4-4856-8eae-42371ccf36e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Submitted batch job 15669650\n"
     ]
    }
   ],
   "source": [
    "## set environment\n",
    "FD_WRK=./\n",
    "FD_LOG=${FD_WRK}/log\n",
    "mkdir -p ${FD_LOG}\n",
    "\n",
    "sbatch -p scavenger \\\n",
    "    --mem 8G \\\n",
    "    -o ${FD_LOG}/model_trivial_v1.txt \\\n",
    "    <<'EOF'\n",
    "#!/bin/bash\n",
    "FD_WRK=./\n",
    "FD_INP=${FD_WRK}/input\n",
    "FD_OUT=${FD_WRK}/output\n",
    "${FD_WRK}/model sample \\\n",
    "    thin=1 num_samples=1000 num_warmup=100 \\\n",
    "    init=${FD_INP}/init.json \\\n",
    "    data   file=${FD_INP}/input_trivial_v1.json \\\n",
    "    output file=${FD_OUT}/output_trivial_v1.csv\n",
    "EOF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3731dba3-ab5f-4777-8e73-e4951495274d",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "method = sample (Default)\n",
      "  sample\n",
      "    num_samples = 1000 (Default)\n",
      "    num_warmup = 100\n",
      "    save_warmup = 0 (Default)\n",
      "    thin = 1 (Default)\n",
      "    adapt\n",
      "      engaged = 1 (Default)\n",
      "      gamma = 0.050000000000000003 (Default)\n",
      "      delta = 0.80000000000000004 (Default)\n",
      "      kappa = 0.75 (Default)\n",
      "      t0 = 10 (Default)\n",
      "      init_buffer = 75 (Default)\n",
      "      term_buffer = 50 (Default)\n",
      "      window = 25 (Default)\n",
      "    algorithm = hmc (Default)\n",
      "      hmc\n",
      "        engine = nuts (Default)\n",
      "          nuts\n",
      "            max_depth = 10 (Default)\n",
      "        metric = diag_e (Default)\n",
      "        metric_file =  (Default)\n",
      "        stepsize = 1 (Default)\n",
      "        stepsize_jitter = 0 (Default)\n",
      "id = 0 (Default)\n",
      "data\n",
      "  file = .//input/input_trivial_v1.json\n",
      "init = .//input/init.json\n",
      "random\n",
      "  seed = 4021865561 (Default)\n",
      "output\n",
      "  file = .//output/output_trivial_v1.csv\n",
      "  diagnostic_file =  (Default)\n",
      "  refresh = 100 (Default)\n",
      "  sig_figs = -1 (Default)\n",
      "  profile_file = profile.csv (Default)\n",
      "\n",
      "\n",
      "Gradient evaluation took 4.6e-05 seconds\n",
      "1000 transitions using 10 leapfrog steps per transition would take 0.46 seconds.\n",
      "Adjust your expectations accordingly!\n",
      "\n",
      "\n",
      "WARNING: There aren't enough warmup iterations to fit the\n",
      "         three stages of adaptation as currently configured.\n",
      "         Reducing each adaptation stage to 15%/75%/10% of\n",
      "         the given number of warmup iterations:\n",
      "           init_buffer = 15\n",
      "           adapt_window = 75\n",
      "           term_buffer = 10\n",
      "\n",
      "Iteration:    1 / 1100 [  0%]  (Warmup)\n",
      "Informational Message: The current Metropolis proposal is about to be rejected because of the following issue:\n",
      "Exception: neg_binomial_2_lpmf: Location parameter is inf, but must be positive finite! (in '/hpc/home/kk319/GitRepo/Proj_CombEffect_STARRseq/notebooks/12_model_sliding/model.stan', line 48, column 12 to column 92)\n",
      "If this warning occurs sporadically, such as for highly constrained variable types like covariance matrices, then the sampler is fine,\n",
      "but if this warning occurs often then your model may be either severely ill-conditioned or misspecified.\n",
      "\n",
      "Informational Message: The current Metropolis proposal is about to be rejected because of the following issue:\n",
      "Exception: neg_binomial_2_lpmf: Location parameter is inf, but must be positive finite! (in '/hpc/home/kk319/GitRepo/Proj_CombEffect_STARRseq/notebooks/12_model_sliding/model.stan', line 48, column 12 to column 92)\n",
      "If this warning occurs sporadically, such as for highly constrained variable types like covariance matrices, then the sampler is fine,\n",
      "but if this warning occurs often then your model may be either severely ill-conditioned or misspecified.\n",
      "\n",
      "Iteration:  100 / 1100 [  9%]  (Warmup)\n",
      "Iteration:  101 / 1100 [  9%]  (Sampling)\n",
      "Iteration:  200 / 1100 [ 18%]  (Sampling)\n",
      "Iteration:  300 / 1100 [ 27%]  (Sampling)\n",
      "Iteration:  400 / 1100 [ 36%]  (Sampling)\n",
      "Iteration:  500 / 1100 [ 45%]  (Sampling)\n",
      "Iteration:  600 / 1100 [ 54%]  (Sampling)\n",
      "Iteration:  700 / 1100 [ 63%]  (Sampling)\n",
      "Iteration:  800 / 1100 [ 72%]  (Sampling)\n",
      "Iteration:  900 / 1100 [ 81%]  (Sampling)\n",
      "Iteration: 1000 / 1100 [ 90%]  (Sampling)\n",
      "Iteration: 1100 / 1100 [100%]  (Sampling)\n",
      "\n",
      " Elapsed Time: 0.155 seconds (Warm-up)\n",
      "               1.337 seconds (Sampling)\n",
      "               1.492 seconds (Total)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cat ${FD_LOG}/model_trivial_v1.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "71a954c2-4355-419e-9fcd-d61f713e6c7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Submitted batch job 15673701\n"
     ]
    }
   ],
   "source": [
    "## set environment\n",
    "FD_WRK=./\n",
    "FD_LOG=${FD_WRK}/log\n",
    "mkdir -p ${FD_LOG}\n",
    "\n",
    "sbatch -p scavenger \\\n",
    "    --mem 8G \\\n",
    "    -o ${FD_LOG}/model_trivial_v2.txt \\\n",
    "    <<'EOF'\n",
    "#!/bin/bash\n",
    "FD_WRK=./\n",
    "FD_INP=${FD_WRK}/input\n",
    "FD_OUT=${FD_WRK}/output\n",
    "FD_MOD=${FD_WRK}/model\n",
    "\n",
    "${FD_MOD}/model sample \\\n",
    "    thin=1 num_samples=1000 num_warmup=100 \\\n",
    "    init=${FD_INP}/init.json \\\n",
    "    data   file=${FD_INP}/input_trivial_v2.json \\\n",
    "    output file=${FD_OUT}/output_trivial_v2.csv\n",
    "EOF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ec0829bc-5626-4197-9aa1-77b5cb60fec5",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "method = sample (Default)\n",
      "  sample\n",
      "    num_samples = 1000 (Default)\n",
      "    num_warmup = 100\n",
      "    save_warmup = 0 (Default)\n",
      "    thin = 1 (Default)\n",
      "    adapt\n",
      "      engaged = 1 (Default)\n",
      "      gamma = 0.050000000000000003 (Default)\n",
      "      delta = 0.80000000000000004 (Default)\n",
      "      kappa = 0.75 (Default)\n",
      "      t0 = 10 (Default)\n",
      "      init_buffer = 75 (Default)\n",
      "      term_buffer = 50 (Default)\n",
      "      window = 25 (Default)\n",
      "    algorithm = hmc (Default)\n",
      "      hmc\n",
      "        engine = nuts (Default)\n",
      "          nuts\n",
      "            max_depth = 10 (Default)\n",
      "        metric = diag_e (Default)\n",
      "        metric_file =  (Default)\n",
      "        stepsize = 1 (Default)\n",
      "        stepsize_jitter = 0 (Default)\n",
      "id = 0 (Default)\n",
      "data\n",
      "  file = .//input/input_trivial_v2.json\n",
      "init = .//input/init.json\n",
      "random\n",
      "  seed = 4028370519 (Default)\n",
      "output\n",
      "  file = .//output/output_trivial_v2.csv\n",
      "  diagnostic_file =  (Default)\n",
      "  refresh = 100 (Default)\n",
      "  sig_figs = -1 (Default)\n",
      "  profile_file = profile.csv (Default)\n",
      "\n",
      "\n",
      "Gradient evaluation took 4.5e-05 seconds\n",
      "1000 transitions using 10 leapfrog steps per transition would take 0.45 seconds.\n",
      "Adjust your expectations accordingly!\n",
      "\n",
      "\n",
      "WARNING: There aren't enough warmup iterations to fit the\n",
      "         three stages of adaptation as currently configured.\n",
      "         Reducing each adaptation stage to 15%/75%/10% of\n",
      "         the given number of warmup iterations:\n",
      "           init_buffer = 15\n",
      "           adapt_window = 75\n",
      "           term_buffer = 10\n",
      "\n",
      "Iteration:    1 / 1100 [  0%]  (Warmup)\n",
      "Iteration:  100 / 1100 [  9%]  (Warmup)\n",
      "Iteration:  101 / 1100 [  9%]  (Sampling)\n",
      "Iteration:  200 / 1100 [ 18%]  (Sampling)\n",
      "Iteration:  300 / 1100 [ 27%]  (Sampling)\n",
      "Iteration:  400 / 1100 [ 36%]  (Sampling)\n",
      "Iteration:  500 / 1100 [ 45%]  (Sampling)\n",
      "Iteration:  600 / 1100 [ 54%]  (Sampling)\n",
      "Iteration:  700 / 1100 [ 63%]  (Sampling)\n",
      "Iteration:  800 / 1100 [ 72%]  (Sampling)\n",
      "Iteration:  900 / 1100 [ 81%]  (Sampling)\n",
      "Iteration: 1000 / 1100 [ 90%]  (Sampling)\n",
      "Iteration: 1100 / 1100 [100%]  (Sampling)\n",
      "\n",
      " Elapsed Time: 0.115 seconds (Warm-up)\n",
      "               0.896 seconds (Sampling)\n",
      "               1.011 seconds (Total)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cat ${FD_LOG}/model_trivial_v2.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92f08a99-df38-4fce-8d53-69e7e4fd466e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d5de0185-2cce-4a60-a939-64a408193b46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Submitted batch job 15673710\n"
     ]
    }
   ],
   "source": [
    "## set environment\n",
    "FD_WRK=./\n",
    "FD_LOG=${FD_WRK}/log\n",
    "mkdir -p ${FD_LOG}\n",
    "\n",
    "sbatch -p scavenger \\\n",
    "    --mem 8G \\\n",
    "    -o ${FD_LOG}/model_trivial_v3.txt \\\n",
    "    <<'EOF'\n",
    "#!/bin/bash\n",
    "FD_WRK=./\n",
    "FD_INP=${FD_WRK}/input\n",
    "FD_OUT=${FD_WRK}/output\n",
    "FD_MOD=${FD_WRK}/model\n",
    "\n",
    "${FD_MOD}/model sample \\\n",
    "    thin=1 num_samples=1000 num_warmup=100 \\\n",
    "    init=${FD_INP}/init.json \\\n",
    "    data   file=${FD_INP}/input_trivial_v3.json \\\n",
    "    output file=${FD_OUT}/output_trivial_v3.csv\n",
    "EOF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "04a0444b-f2e5-435e-8e4d-6a476810df42",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "method = sample (Default)\n",
      "  sample\n",
      "    num_samples = 1000 (Default)\n",
      "    num_warmup = 100\n",
      "    save_warmup = 0 (Default)\n",
      "    thin = 1 (Default)\n",
      "    adapt\n",
      "      engaged = 1 (Default)\n",
      "      gamma = 0.050000000000000003 (Default)\n",
      "      delta = 0.80000000000000004 (Default)\n",
      "      kappa = 0.75 (Default)\n",
      "      t0 = 10 (Default)\n",
      "      init_buffer = 75 (Default)\n",
      "      term_buffer = 50 (Default)\n",
      "      window = 25 (Default)\n",
      "    algorithm = hmc (Default)\n",
      "      hmc\n",
      "        engine = nuts (Default)\n",
      "          nuts\n",
      "            max_depth = 10 (Default)\n",
      "        metric = diag_e (Default)\n",
      "        metric_file =  (Default)\n",
      "        stepsize = 1 (Default)\n",
      "        stepsize_jitter = 0 (Default)\n",
      "id = 0 (Default)\n",
      "data\n",
      "  file = .//input/input_trivial_v3.json\n",
      "init = .//input/init.json\n",
      "random\n",
      "  seed = 4028571590 (Default)\n",
      "output\n",
      "  file = .//output/output_trivial_v3.csv\n",
      "  diagnostic_file =  (Default)\n",
      "  refresh = 100 (Default)\n",
      "  sig_figs = -1 (Default)\n",
      "  profile_file = profile.csv (Default)\n",
      "\n",
      "\n",
      "Gradient evaluation took 4.6e-05 seconds\n",
      "1000 transitions using 10 leapfrog steps per transition would take 0.46 seconds.\n",
      "Adjust your expectations accordingly!\n",
      "\n",
      "\n",
      "WARNING: There aren't enough warmup iterations to fit the\n",
      "         three stages of adaptation as currently configured.\n",
      "         Reducing each adaptation stage to 15%/75%/10% of\n",
      "         the given number of warmup iterations:\n",
      "           init_buffer = 15\n",
      "           adapt_window = 75\n",
      "           term_buffer = 10\n",
      "\n",
      "Informational Message: The current Metropolis proposal is about to be rejected because of the following issue:\n",
      "Exception: neg_binomial_2_lpmf: Location parameter is inf, but must be positive finite! (in '/hpc/home/kk319/GitRepo/Proj_CombEffect_STARRseq/notebooks/12_model_sliding/model.stan', line 48, column 12 to column 92)\n",
      "If this warning occurs sporadically, such as for highly constrained variable types like covariance matrices, then the sampler is fine,\n",
      "but if this warning occurs often then your model may be either severely ill-conditioned or misspecified.\n",
      "\n",
      "Informational Message: The current Metropolis proposal is about to be rejected because of the following issue:\n",
      "Exception: neg_binomial_2_lpmf: Location parameter is inf, but must be positive finite! (in '/hpc/home/kk319/GitRepo/Proj_CombEffect_STARRseq/notebooks/12_model_sliding/model.stan', line 48, column 12 to column 92)\n",
      "If this warning occurs sporadically, such as for highly constrained variable types like covariance matrices, then the sampler is fine,\n",
      "but if this warning occurs often then your model may be either severely ill-conditioned or misspecified.\n",
      "\n",
      "Informational Message: The current Metropolis proposal is about to be rejected because of the following issue:\n",
      "Exception: neg_binomial_2_lpmf: Location parameter is inf, but must be positive finite! (in '/hpc/home/kk319/GitRepo/Proj_CombEffect_STARRseq/notebooks/12_model_sliding/model.stan', line 48, column 12 to column 92)\n",
      "If this warning occurs sporadically, such as for highly constrained variable types like covariance matrices, then the sampler is fine,\n",
      "but if this warning occurs often then your model may be either severely ill-conditioned or misspecified.\n",
      "\n",
      "Iteration:    1 / 1100 [  0%]  (Warmup)\n",
      "Informational Message: The current Metropolis proposal is about to be rejected because of the following issue:\n",
      "Exception: neg_binomial_2_lpmf: Location parameter is inf, but must be positive finite! (in '/hpc/home/kk319/GitRepo/Proj_CombEffect_STARRseq/notebooks/12_model_sliding/model.stan', line 48, column 12 to column 92)\n",
      "If this warning occurs sporadically, such as for highly constrained variable types like covariance matrices, then the sampler is fine,\n",
      "but if this warning occurs often then your model may be either severely ill-conditioned or misspecified.\n",
      "\n",
      "Informational Message: The current Metropolis proposal is about to be rejected because of the following issue:\n",
      "Exception: neg_binomial_2_lpmf: Location parameter is inf, but must be positive finite! (in '/hpc/home/kk319/GitRepo/Proj_CombEffect_STARRseq/notebooks/12_model_sliding/model.stan', line 48, column 12 to column 92)\n",
      "If this warning occurs sporadically, such as for highly constrained variable types like covariance matrices, then the sampler is fine,\n",
      "but if this warning occurs often then your model may be either severely ill-conditioned or misspecified.\n",
      "\n",
      "Iteration:  100 / 1100 [  9%]  (Warmup)\n",
      "Iteration:  101 / 1100 [  9%]  (Sampling)\n",
      "Iteration:  200 / 1100 [ 18%]  (Sampling)\n",
      "Iteration:  300 / 1100 [ 27%]  (Sampling)\n",
      "Iteration:  400 / 1100 [ 36%]  (Sampling)\n",
      "Iteration:  500 / 1100 [ 45%]  (Sampling)\n",
      "Iteration:  600 / 1100 [ 54%]  (Sampling)\n",
      "Iteration:  700 / 1100 [ 63%]  (Sampling)\n",
      "Iteration:  800 / 1100 [ 72%]  (Sampling)\n",
      "Iteration:  900 / 1100 [ 81%]  (Sampling)\n",
      "Iteration: 1000 / 1100 [ 90%]  (Sampling)\n",
      "Iteration: 1100 / 1100 [100%]  (Sampling)\n",
      "\n",
      " Elapsed Time: 0.112 seconds (Warm-up)\n",
      "               1.218 seconds (Sampling)\n",
      "               1.33 seconds (Total)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cat ${FD_LOG}/model_trivial_v3.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40b8b738-8d0b-4ad3-896b-b1a550c40ec1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "aa78b57b-4e0d-4626-92c7-a1cbe090fb9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Submitted batch job 15673733\n"
     ]
    }
   ],
   "source": [
    "## set environment\n",
    "FD_WRK=./\n",
    "FD_LOG=${FD_WRK}/log\n",
    "mkdir -p ${FD_LOG}\n",
    "\n",
    "sbatch -p scavenger \\\n",
    "    --mem 8G \\\n",
    "    -o ${FD_LOG}/model_trivial_v4.txt \\\n",
    "    <<'EOF'\n",
    "#!/bin/bash\n",
    "FD_WRK=./\n",
    "FD_INP=${FD_WRK}/input\n",
    "FD_OUT=${FD_WRK}/output\n",
    "FD_MOD=${FD_WRK}/model\n",
    "\n",
    "${FD_MOD}/model sample \\\n",
    "    thin=1 num_samples=1000 num_warmup=100 \\\n",
    "    init=${FD_INP}/init.json \\\n",
    "    data   file=${FD_INP}/input_trivial_v4.json \\\n",
    "    output file=${FD_OUT}/output_trivial_v4.csv\n",
    "EOF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83684594-3d4e-47f3-9605-5723571b75a6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Bash",
   "language": "bash",
   "name": "bash"
  },
  "language_info": {
   "codemirror_mode": "shell",
   "file_extension": ".sh",
   "mimetype": "text/x-sh",
   "name": "bash"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
